## Objective

Sai-Challenger allows setup huge sized configuration. These configuration are generated by external tool named **Generate SAI**.
Configurations could be applied by different appliance APIs (SONiC Orchagent, SAI thrift, etc.).
After that appliance could be tested using various traffic generators (Snappi/OTG, Ptf, etc.).
Sai-Challenger plays as mediator between this sub-systems, and this achieved by:

* Providing
  * DSL for appliance dataplane configuration & testing
  * DSL for appliance configuration
  * DSL for appliance API

Also Sai-Challenger is a testing tool, so it provides meaningful test preconditions and setups

<a href="url"><img src="../img/DASH test framework-DASH Syncer HL.drawio.svg" align="center" width="800" ></a>

Possibility to use various SAI API wrappers is achieved by the next architecture

<a href="url"><img src="../img/DASH test framework-DASH Syncer(Detailed).drawio.svg" align="center" width="800" ></a>

Typical test execution happen in the next manner
* pytest starts and get paths to test framework configurations
* configurations are passed to sai_environment setup script
* sai_environment loads accessible implementations and forms test environment model
  * configuration could include appliances of different types, every of which could be setup with its own API
  * traffic also could be sent and validated using various traffic generators
* Sai is started
* Setup is loaded to appliance
* Traffic is sent and captured

Because of above schema Sai class don't have to know anything about low-API level and because of this appliance could
be setup using same commands using different API backends. Same for traffic generation/validation tools